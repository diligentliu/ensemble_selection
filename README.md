# Ensemble Selection based on Classifier Prediction Confidence

关于这篇论文的复现<https://doi.org/10.1016/j.patcog.2019.107104>

文章提出了一种基于分类预测置信度的集成学习方法，简单来说，比如说我跟一个大佬，我对大家说这个值是一的概率是0.5是0的概率也是0.5，大佬对大伙儿说，这个值八成概率是 1，那大伙肯定更相信大佬的话，文章定义了一个loss函数，根据人工蜂群算法(Artificial Bee Colony Algorithm, ABC)来优化求解一个阈值，再计算预测的熵值（代码用的是香农熵），对于二分类而言，熵值越大，两个概率相差就越大，也就是前文所说的大佬认为的 0.8 和 0.2如果预测的熵值大于阈值，则这次预测不参与集成学习，如果小于这个阈值，则参与集成学习。